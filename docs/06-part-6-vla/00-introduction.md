---
title: "Part 6: Cognitive Robotics"
description: "VLA and LLMs"
---

# Part 6: Cognitive Robotics (VLA)

## Module Overview
The final frontier is giving the robot a "mind". By integrating Large Language Models (LLMs) and Vision-Language-Action (VLA) models, we can create robots that understand natural language and reason about the world.

## Learning Objectives
In this module, you will:
*   Understand the **VLA** paradigm (RT-2, Optimus).
*   Use **OpenAI Whisper** for voice interaction.
*   Build a **Cognitive Planner** that translates "I'm hungry" into robot actions.
*   Integrate everything into a final **Autonomous Humanoid**.

## Chapters
*   **[Chapter 9: Vision-Language-Action](./01-chapter-9-vla.md)**
*   **[Chapter 10: Capstone - The Autonomous Humanoid](./02-chapter-10-conversational.md)**
