---
id: chapter-5-high-fidelity-simulation
title: "Chapter 5: High-Fidelity Simulation"
sidebar_label: "5. High-Fidelity & Unity"
---

# High-Fidelity Simulation and Sensor Modeling

## 5.1 Beyond Gazebo: The Need for High-Fidelity

Gazebo is great for physics, but older versions lack photorealism. For **Visual AI** (Object Detection, VSLAM), we need simulators that look like the real world.

**Unity** and **Unreal Engine** are game engines repurposed for robotics to provide:
*   **Ray-Tracing**: Realistic lighting, shadows, and reflections.
*   **Physics**: NVidia PhysX (Unity) or Chaos (Unreal).
*   **Assets**: Access to millions of 3D models (tables, chairs, houses).

## 5.2 Simulating Sensors

A robot relies on its sensors. We must model them accurately, including their noise and imperfections.

### 5.2.1 LiDAR Simulation
LiDAR implies "Light Detection and Ranging".
*   **Ray Casting**: The simulator shoots thousands of rays (lines) from the sensor origin.
*   **Intersection**: Calculates where rays hit the geometry.
*   **Noise**: Real LiDARs have error. We add Gaussian noise to the range data to simulate reality (z = z_true + N(0, Ïƒ^2)).

### 5.2.2 Depth Cameras
Simulating an Intel RealSense D435i.
*   **Technique**: Render the scene from the camera's perspective. The Z-buffer (depth buffer) of the graphics card gives the distance to every pixel perfectly.
*   **Artifacts**: Real depth cameras fail on shiny surfaces (mirrors) or deep black objects. High-end sims model these failures.

### 5.2.3 IMU (Inertial Measurement Unit)
*   **Bias and Drift**: Real IMUs drift over time. Simulators model:
    *   *White Noise*: Random variance.
    *   *Random Walk*: The bias slowly wanders over time.

## 5.3 Unity for Robotics

Interfacing ROS 2 with Unity is done via the **ROS-TCP-Connector**.

### Architecture
1.  **Unity**: Runs the physics and rendering.
2.  **ROS-TCP-Endpoint**: A ROS node acting as a server.
3.  **ROS-TCP-Connector**: A C# script in Unity sending data to the Endpoint.

### Example: Publishing an Image from Unity
1.  Add a Camera in Unity.
2.  Add a `RosPublisher` script.
3.  Topic Name: `/unity/camera/image_raw`.
4.  Message Type: `sensor_msgs/Image`.

When you hit "Play" in Unity, your ROS 2 terminal will receive 60fps HD video streams generated by the game engine.

## 5.4 Human-Robot Interaction (HRI) in Sim

Unity is ideal for HRI. You can use VR headsets to step *into* the simulation and interact with your robot.
*   **Teleoperation**: Control the robot arms using VR controllers.
*   **Safety Testing**: stand near the robot in VR to see if it stops safely (without risking your real physical safety).

## 5.5 Conclusion

We now have two simulation tools:
1.  **Gazebo**: Fast, standard, good for dynamics checks.
2.  **Unity**: Beautiful, sensor-rich, good for Vision AI and HRI.

Next, we look at the industry standard for professional Physical AI: **NVIDIA Isaac**.
